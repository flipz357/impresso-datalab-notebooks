{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect entities in a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named entities such as organizations, locations, persons, and temporal expressions play a crucial role in the comprehension and analysis of both historical and contemporary texts. The HIPE-2022 project focuses on named entity recognition and classification (NERC) and entity linking (EL) in multilingual historical documents.\n",
    "\n",
    "### About HIPE-2022\n",
    "HIPE-2022 involves processing diverse datasets from historical newspapers and classical commentaries, spanning approximately 200 years and multiple languages. The primary goal is to confront systems with challenges related to multilinguality, domain-specific entities, and varying annotation tag sets.\n",
    "\n",
    "### Datasets\n",
    "The HIPE-2022 datasets are based on six primary datasets, but this model was only trained on **hipe2020** in French and German.\n",
    "- **ajmc**: Classical commentaries in German, French, and English.\n",
    "- **hipe2020**: Historical newspapers in German, French, and English.\n",
    "- **letemps**: Historical newspapers in French.\n",
    "- **topres19th**: Historical newspapers in English.\n",
    "- **newseye**: Historical newspapers in German, Finnish, French, and Swedish.\n",
    "- **sonar**: Historical newspapers in German.\n",
    "\n",
    "### Annotation Types and Levels\n",
    "HIPE-2022 employs an IOB tagging scheme (inside-outside-beginning format) for entity annotations. The annotation levels include:\n",
    "\n",
    "1. **TOKEN**: The annotated token.\n",
    "2. **NE-COARSE-LIT**: Coarse type of the entity (literal sense).\n",
    "3. **NE-COARSE-METO**: Coarse type of the entity (metonymic sense).\n",
    "4. **NE-FINE-LIT**: Fine-grained type of the entity (literal sense).\n",
    "5. **NE-FINE-METO**: Fine-grained type of the entity (metonymic sense).\n",
    "6. **NE-FINE-COMP**: Component type of the entity.\n",
    "7. **NE-NESTED**: Coarse type of the nested entity.\n",
    "\n",
    "### Getting Started\n",
    "This notebook will guide you through setting up a workflow to identify named entities within your text using the HIPE-2022 trained pipeline. By leveraging this pipeline, you can detect mentions of people, places, organizations, and temporal expressions, enhancing your analysis and understanding of historical and contemporary documents.\n",
    "\n",
    "---\n",
    "\n",
    "This updated description provides a clear overview of the HIPE-2022 project's goals, datasets, and annotation types, focusing on the identification of generic named entities in multilingual historical documents.\n",
    "*Note: This notebook *might* require `HF_TOKEN` to be set in the environment variables. You can get your token by signing up on the [Hugging Face website](https://huggingface.co/join) and read more in the [official documentation](https://huggingface.co/docs/huggingface_hub/v0.20.2/en/quick-start#environment-variable)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install necessary libraries (if not already installed) and \n",
    "download the necessary NLTK data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13902,
     "status": "ok",
     "timestamp": 1712593966254,
     "user": {
      "displayName": "c2dh automaton",
      "userId": "06595644132255672638"
     },
     "user_tz": -120
    },
    "id": "eC4L37FtjYe-",
    "outputId": "b4126877-f531-4a91-ef9c-93b2d6e6a2e5"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install nltk\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having installed the necessary libraries (if not already installed) we download the necessary NLTK data to run our POS tagger: **averaged_perceptron_tagger**.\n",
    "The averaged_perceptron_tagger is a efficient and effective part-of-speech (POS) tagger that basically tag each word in a sentence with its corresponding part of speech, such as noun, verb, adjective, etc. See [https://arxiv.org/abs/2104.02831](https://arxiv.org/abs/2104.02831) as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1712594294715,
     "user": {
      "displayName": "c2dh automaton",
      "userId": "06595644132255672638"
     },
     "user_tz": -120
    },
    "id": "_UXo-c8aks_p",
    "outputId": "d1448337-3cc3-4ccc-de6b-b3edd251cb5c"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the fun part, this function will download the requried model and gives you the keys to successfullly detect news agencies in your text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from the transformers library\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# Define the model name to be used for token classification, we use the Impresso NER\n",
    "MODEL_NAME = \"impresso-project/ner-stacked-bert-multilingual\"\n",
    "\n",
    "# Load the tokenizer corresponding to the specified model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for named entity recognition (NER) using the loaded model and tokenizer\n",
    "nlp = pipeline(\"generic-ner\", model=MODEL_NAME, tokenizer=tokenizer, trust_remote_code=True)\n",
    "\n",
    "# Input text to be processed for named entity recognition\n",
    "results = nlp(\"\"\"Apple est créée le 1er avril 1976 dans le garage de la maison \n",
    "            d'enfance de Steve Jobs à Los Altos en Californie par Steve Jobs, Steve Wozniak \n",
    "            et Ronald Wayne14, puis constituée sous forme de société le 3 janvier 1977 à l'origine \n",
    "            sous le nom d'Apple Computer, mais pour ses 30 ans et pour refléter la diversification \n",
    "            de ses produits, le mot « computer » est retiré le 9 janvier 2015.\n",
    "            \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nicely(results):\n",
    "    for key, entities in results.items():\n",
    "        if entities:\n",
    "            print(f\"\\n**{key}**\\n\")\n",
    "            print(f\"{'Entity':<15} {'Type':<10} {'Score':<8} {'Index':<5} {'Word':<20} {'Start':<5} {'End':<5}\")\n",
    "            print(\"-\" * 70)\n",
    "            for entity in entities:\n",
    "                print(f\"{entity['word']:<15} {entity['entity']:<10} {entity['score']:<8.4f} {entity['index']:<5} {entity['word']:<20} {entity['start']:<5} {entity['end']:<5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**NE-COARSE-LIT**\n",
      "\n",
      "Entity          Type       Score    Index Word                 Start End  \n",
      "----------------------------------------------------------------------\n",
      "Apple           loc        0.4756   0     Apple                0     5    \n",
      "Apple           loc        0.4756   0     Apple                282   287  \n",
      "le 1er avril 1976 time       0.8420   3     le 1er avril 1976    16    33   \n",
      "Steve Jobs      pers       0.8601   17    Steve Jobs           88    98   \n",
      "Steve Jobs      pers       0.8601   17    Steve Jobs           129   139  \n",
      "Los Altos       loc        0.9740   20    Los Altos            101   110  \n",
      "Californie      loc        0.9822   23    Californie           114   124  \n",
      "Steve Jobs      pers       0.8479   25    Steve Jobs           88    98   \n",
      "Steve Jobs      pers       0.8479   25    Steve Jobs           129   139  \n",
      "Steve Wozniak   pers       0.8791   28    Steve Wozniak        141   154  \n",
      "Ronald Wayne14  pers       0.8972   31    Ronald Wayne14       171   185  \n",
      "le 3 janvier 1977 time       0.8917   40    le 3 janvier 1977    225   242  \n",
      "Apple Computer  org        0.8271   53    Apple Computer       282   296  \n",
      "le 9 janvier 2015 time       0.8830   77    le 9 janvier 2015    416   433  \n",
      "\n",
      "**NE-FINE-LIT**\n",
      "\n",
      "Entity          Type       Score    Index Word                 Start End  \n",
      "----------------------------------------------------------------------\n",
      "Apple           loc.adm.town 0.4350   0     Apple                0     5    \n",
      "Apple           loc.adm.town 0.4350   0     Apple                282   287  \n",
      "le 1er avril 1976 time.date.abs 0.8618   3     le 1er avril 1976    16    33   \n",
      "Steve Jobs      pers.ind   0.7488   17    Steve Jobs           88    98   \n",
      "Steve Jobs      pers.ind   0.7488   17    Steve Jobs           129   139  \n",
      "Los Altos       loc.adm.town 0.6634   20    Los Altos            101   110  \n",
      "Californie      loc.adm.nat 0.3789   23    Californie           114   124  \n",
      "Steve Jobs      pers.ind   0.7335   25    Steve Jobs           88    98   \n",
      "Steve Jobs      pers.ind   0.7335   25    Steve Jobs           129   139  \n",
      "Steve Wozniak   pers.ind   0.7881   28    Steve Wozniak        141   154  \n",
      "Ronald Wayne14  pers.ind   0.8401   31    Ronald Wayne14       171   185  \n",
      "le 3 janvier 1977 time.date.abs 0.9146   40    le 3 janvier 1977    225   242  \n",
      "Apple Computer  org.ent    0.8213   53    Apple Computer       282   296  \n",
      "le 9 janvier 2015 time.date.abs 0.9058   77    le 9 janvier 2015    416   433  \n"
     ]
    }
   ],
   "source": [
    "print_nicely(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOKXk4sqe0yBXtOpC+Z4ngA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
