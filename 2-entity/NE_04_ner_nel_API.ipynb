{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P374GZ3Nxusx"
      },
      "source": [
        "# Detect Entities and Link them to Wikipedia and Wikidata in a Text through the Impresso API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSY3E8j5xusy"
      },
      "source": [
        "We refer to \"named entity recognition\" as NER, which is a tool that recognises entities such as persons and locations from text. A \"named entity linker\" (NEL) connects these entities to an existing one such as a real person that can be found on Wikipedia (with a unique id in Wikidata). Wikipedia is a free, user-edited encyclopedia with articles on a wide range of topics like historical events, famous people, or scientific concepts. Wikidata is a sister project of Wikipedia that stores structured data, like facts and relationships between entities, used for tasks where computers need to understand and process data, such as NER and NEL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if8onHfRxusz"
      },
      "source": [
        "In the context of _Impresso_, the NER tool was trained on the [HIPE 2020](https://github.com/hipe-eval/HIPE-2022-data/blob/main/documentation/README-hipe2020.md) dataset. It was trained to recognise coarse and fine grained entities such as persons and locations, but also their names, titles, and functions. Further, the _Impresso_ NEL tool links these entity mentions to unique referents in a knowledge base – here Wikipedia and Wikidata – or not if the mention's referent is not found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC4L37FtjYe-",
        "outputId": "26a08fc9-4511-4fdf-ee99-1fd75a7aca82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "--2024-09-30 12:30:21--  https://raw.githubusercontent.com/impresso/impresso-datalab-notebooks/3f7afc05caef3f527db8320cdf8c131aec41d7cd/2-entity/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5625 (5.5K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py            100%[===================>]   5.49K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-30 12:30:21 (62.4 MB/s) - ‘utils.py’ saved [5625/5625]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!wget https://raw.githubusercontent.com/impresso/impresso-datalab-notebooks/3f7afc05caef3f527db8320cdf8c131aec41d7cd/2-entity/utils.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5xfGodjxus0"
      },
      "outputs": [],
      "source": [
        "def print_nicely(results, text):\n",
        "    # Print the timestamp and system ID\n",
        "    print(f\"Timestamp: {results.get('ts')}\")\n",
        "    print(f\"System ID: {results.get('sys_id')}\")\n",
        "\n",
        "    entities = results.get('nes', [])\n",
        "    if entities:\n",
        "        print(f\"\\n{'Entity':<20} {'Type':<15} {'Confidence NER':<15} {'Confidence NEL':<15} {'Start':<5} {'End':<5} {'Wikidata ID':<10} {'Wikipedia Page':<20}\")\n",
        "        print(\"-\" * 100)\n",
        "        for entity in entities:\n",
        "            confidence_ner = f\"{entity['confidence_ner']}%\"\n",
        "            confidence_nel = f\"{entity['confidence_nel']}%\"\n",
        "            wkd_id = entity.get('wkd_id', 'N/A')\n",
        "            wkpedia_pagename = entity.get('wkpedia_pagename', 'N/A')\n",
        "            print(f\"{entity['surface']:<20} {entity['type']:<15} {confidence_ner:<15} {confidence_nel:<15} {entity['lOffset']:<5} {entity['rOffset']:<5} {wkd_id:<10} {wkpedia_pagename:<20}\")\n",
        "\n",
        "        print(\"*\" * 100)\n",
        "        print('Testing offsets:')\n",
        "        print(\"*\" * 100)\n",
        "        print(f\"\\n{'Entity':<20} {'Type':<15} {'Confidence NER':<15} {'Confidence NEL':<15} {'Start':<5} {'End':<5} {'Wikidata ID':<10} {'Wikipedia Page':<20}\")\n",
        "        print(\"-\" * 100)\n",
        "        for entity in entities:\n",
        "            confidence_ner = f\"{entity['confidence_ner']}%\"\n",
        "            confidence_nel = f\"{entity['confidence_nel']}%\"\n",
        "            wkd_id = entity.get('wkd_id', 'N/A')\n",
        "            wkpedia_pagename = entity.get('wkpedia_pagename', 'N/A')\n",
        "            print(f\"{text[entity['lOffset']:entity['rOffset']]:<20} {entity['type']:<15} {confidence_ner:<15} {confidence_nel:<15} {entity['lOffset']:<5} {entity['rOffset']:<5} {wkd_id:<10} {wkpedia_pagename:<20}\")\n",
        "\n",
        "        print(\"*\" * 100)\n",
        "        print('Testing offsets in the returned text:')\n",
        "        print(\"*\" * 100)\n",
        "        print(f\"\\n{'Entity':<20} {'Type':<15} {'Confidence NER':<15} {'Confidence NEL':<15} {'Start':<5} {'End':<5} {'Wikidata ID':<10} {'Wikipedia Page':<20}\")\n",
        "        print(\"-\" * 100)\n",
        "        for entity in entities:\n",
        "            confidence_ner = f\"{entity['confidence_ner']}%\"\n",
        "            confidence_nel = f\"{entity['confidence_nel']}%\"\n",
        "            wkd_id = entity.get('wkd_id', 'N/A')\n",
        "            wkpedia_pagename = entity.get('wkpedia_pagename', 'N/A')\n",
        "            print(f\"{results['text'][entity['lOffset']:entity['rOffset']]:<20} {entity['type']:<15} {confidence_ner:<15} {confidence_nel:<15} {entity['lOffset']:<5} {entity['rOffset']:<5} {wkd_id:<10} {wkpedia_pagename:<20}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGY-Vwvqxus0"
      },
      "source": [
        "Now the fun part, this function will download the requried model and gives you the keys to successfullly detect entities in your text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXIIRNL3xus1",
        "outputId": "cc9e5e7b-61e9-4723-e93f-fca865698ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Timestamp: 2024-09-30T14:30:38Z\n",
            "System ID: ner-stacked-2-bert-medium-historic-multilingual\n",
            "\n",
            "Entity               Type            Confidence NER  Confidence NEL  Start End   Wikidata ID Wikipedia Page      \n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'confidence_nel'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-2eb74fa05bfe>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linked_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint_nicely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-d0e6f35892da>\u001b[0m in \u001b[0;36mprint_nicely\u001b[0;34m(results, text)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mconfidence_ner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{entity['confidence_ner']}%\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mconfidence_nel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{entity['confidence_nel']}%\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mwkd_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wkd_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'N/A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mwkpedia_pagename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wkpedia_pagename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'N/A'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'confidence_nel'"
          ]
        }
      ],
      "source": [
        "from utils import get_linked_entities\n",
        "import requests\n",
        "\n",
        "sentences = [\"Apple est créée le 1er avril 1976 dans le garage de la maison d'enfance de Steve Jobs à Los Altos en Californie par Steve Jobs, Steve Wozniak et Ronald Wayne, puis constituée sous forme de société le 3 janvier 1977 à l'origine sous le nom d'Apple Computer, mais pour ses 30 ans et pour refléter la diversification de ses produits, le mot « computer » est retiré le 9 janvier 2015.\"]\n",
        "\n",
        "for sentence in sentences:\n",
        "    results = get_linked_entities(sentence)\n",
        "    print_nicely(results, sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYWMO8QFxus1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## About Impresso\n",
        "\n",
        "### Impresso project\n",
        "\n",
        "[Impresso - Media Monitoring of the Past](https://impresso-project.ch) is an\n",
        "interdisciplinary research project that aims to develop and consolidate tools for\n",
        "processing and exploring large collections of media archives across modalities, time,\n",
        "languages and national borders. The first project (2017-2021) was funded by the Swiss\n",
        "National Science Foundation under grant\n",
        "No. [CRSII5_173719](http://p3.snf.ch/project-173719) and the second project (2023-2027)\n",
        "by the SNSF under grant No. [CRSII5_213585](https://data.snf.ch/grants/grant/213585)\n",
        "and the Luxembourg National Research Fund under grant No. 17498891.\n",
        "\n",
        "### Copyright\n",
        "\n",
        "Copyright (C) 2024 The Impresso team.\n",
        "\n",
        "### License\n",
        "\n",
        "This program is provided as open source under\n",
        "the [GNU Affero General Public License](https://github.com/impresso/impresso-pyindexation/blob/master/LICENSE)\n",
        "v3 or later.\n",
        "\n",
        "---\n",
        "\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://github.com/impresso/impresso.github.io/blob/master/assets/images/3x1--Yellow-Impresso-Black-on-White--transparent.png?raw=true\" width=\"350\" alt=\"Impresso Project Logo\"/>\n",
        "</p>\n"
      ],
      "metadata": {
        "id": "3Q9XStpV6ZI8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4_8lF2rxus2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeInYGAKxus2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIbSdkYbxus3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "115cX4hMxus3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLd95YnMxus3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLckw0Egxus3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABlst2l0xus3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}