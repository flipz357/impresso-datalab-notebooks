{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4982c90e1ce34f5f",
   "metadata": {},
   "source": [
    "# Named Entity Recognition and Linking with Impresso BERT models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a706a1074ca4c",
   "metadata": {},
   "source": [
    "## Good to know before starting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53cadc-8949-4089-b224-19084ecc1c97",
   "metadata": {},
   "source": [
    "We refer to \"named entity recognition\" as NER, which is a tool that recognises entities such as persons and locations from text. A \"named entity linker\" (NEL) connects these entities to an existing one such as a real person that can be found on Wikipedia (with a unique id in Wikidata). Wikipedia is a free, user-edited encyclopedia with articles on a wide range of topics like historical events, famous people, or scientific concepts. Wikidata is a sister project of Wikipedia that stores structured data, like facts and relationships between entities, used for tasks where computers need to understand and process data, such as NER and NEL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f165f0-123c-4bd3-9acd-0b185644c739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c784118d-577c-4a7e-8c3f-38610635bb3f",
   "metadata": {},
   "source": [
    "In the context of _Impresso_, the NER tool was trained on the [HIPE 2020](https://github.com/hipe-eval/HIPE-2022-data/blob/main/documentation/README-hipe2020.md) dataset. It was trained to recognise coarse and fine grained entities such as persons and locations, but also their names, titles, and functions. Further, the _Impresso_ NEL tool links these entity mentions to unique referents in a knowledge base – here Wikipedia and Wikidata – or not if the mention's referent is not found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239e629-a165-43b7-bccc-e87e50aaa7e9",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c6a38a7-190e-47cb-8f90-01b8147e1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.45.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
      "Downloading safetensors-0.4.5-cp312-cp312-macosx_11_0_arm64.whl (381 kB)\n",
      "Downloading tokenizers-0.20.0-cp312-cp312-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.25.1 safetensors-0.4.5 tokenizers-0.20.0 transformers-4.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9ae812-2faf-4bf7-9c50-b5734ce18e1b",
   "metadata": {},
   "source": [
    "## Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9ddfc8e-7b7a-40a3-9379-65a9372eb8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/rv/x6hk7f3j7dzb763m4m3kgmb00000gp/T/ipykernel_4878/197571163.py\", line 2, in <module>\n",
      "    from transformers import pipeline\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1754, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 1764, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/__init__.py\", line 62, in <module>\n",
      "    from .document_question_answering import DocumentQuestionAnsweringPipeline\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py\", line 29, in <module>\n",
      "    from .question_answering import select_starts_ends\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/question_answering.py\", line 9, in <module>\n",
      "    from ..data import SquadExample, SquadFeatures, squad_convert_examples_to_features\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/data/__init__.py\", line 27, in <module>\n",
      "    from .metrics import glue_compute_metrics, xnli_compute_metrics\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/data/metrics/__init__.py\", line 19, in <module>\n",
      "    from scipy.stats import pearsonr, spearmanr\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/__init__.py\", line 606, in <module>\n",
      "    from ._stats_py import *\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/_stats_py.py\", line 37, in <module>\n",
      "    from scipy import sparse\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/scipy/__init__.py\", line 134, in __getattr__\n",
      "    return _importlib.import_module(f'scipy.{name}')\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/scipy/sparse/__init__.py\", line 295, in <module>\n",
      "    from ._csr import *\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/scipy/sparse/_csr.py\", line 11, in <module>\n",
      "    from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.1.1 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nnumpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1764\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/__init__.py:62\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdepth_estimation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DepthEstimationPipeline\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_question_answering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocumentQuestionAnsweringPipeline\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureExtractionPipeline\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/document_question_answering.py:29\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkPipeline, build_pipeline_init_args\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquestion_answering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m select_starts_ends\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_vision_available():\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SquadExample, SquadFeatures, squad_convert_examples_to_features\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodelcard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelCard\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/data/__init__.py:27\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_collator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     DataCollatorForLanguageModeling,\n\u001b[1;32m     17\u001b[0m     DataCollatorForPermutationLanguageModeling,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     default_data_collator,\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m glue_compute_metrics, xnli_compute_metrics\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprocessors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     DataProcessor,\n\u001b[1;32m     30\u001b[0m     InputExample,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     xnli_tasks_num_labels,\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/data/metrics/__init__.py:19\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sklearn_available():\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pearsonr, spearmanr\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score, matthews_corrcoef\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/__init__.py:606\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    605\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/stats/_stats_py.py:37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cdist\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/__init__.py:134\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscipy.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/sparse/__init__.py:295\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/scipy/sparse/_csr.py:11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _spbase, sparray\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sparsetools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[1;32m     12\u001b[0m                            get_csr_submatrix)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m upcast\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import necessary modules from the transformers library\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForTokenClassification, AutoTokenizer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Define the model name to be used for token classification, we use the Impresso NER\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# that can be foud at \"https://huggingface.co/impresso-project/ner-stacked-bert-multilingual\"\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1754\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1752\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1754\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m   1755\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1766\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1767\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1768\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1769\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.pipelines because of the following error (look up to see its traceback):\nnumpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "# Import necessary modules from the transformers library\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "# Define the model name to be used for token classification, we use the Impresso NER\n",
    "# that can be foud at \"https://huggingface.co/impresso-project/ner-stacked-bert-multilingual\"\n",
    "MODEL_NAME = \"impresso-project/ner-stacked-bert-multilingual\"\n",
    "\n",
    "# Load the tokenizer corresponding to the specified model name\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84545a0f-4f7e-49f5-b48c-7540cca32afc",
   "metadata": {},
   "source": [
    "Create a pipeline for named entity recognition (NER) using the loaded model and tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c04b662-a9b2-452b-8bb4-aa99213b9c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/eboros/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"generic-ner\", model=MODEL_NAME, tokenizer=tokenizer, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82fe3227-fcce-4323-8ba7-ea6a357fe5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple est créée le 1er avril 1976 dans le garage de la maison \n",
      "            d'enfance de Steve Jobs à Los Altos en Californie par Steve Jobs, Steve Wozniak \n",
      "            et Ronald Wayne, puis constituée sous forme de société le 3 janvier 1977 à l'origine \n",
      "            sous le nom d'Apple Computer, mais pour ses 30 ans et pour refléter la diversification \n",
      "            de ses produits, le mot « computer » est retiré le 9 janvier 2015.\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "sentences = [\"\"\"Apple est créée le 1er avril 1976 dans le garage de la maison \n",
    "            d'enfance de Steve Jobs à Los Altos en Californie par Steve Jobs, Steve Wozniak \n",
    "            et Ronald Wayne, puis constituée sous forme de société le 3 janvier 1977 à l'origine \n",
    "            sous le nom d'Apple Computer, mais pour ses 30 ans et pour refléter la diversification \n",
    "            de ses produits, le mot « computer » est retiré le 9 janvier 2015.\n",
    "            \"\"\"]\n",
    "\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba0cf70-fd9a-4e82-a5fa-3d5bcecef305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Visualizing stacked coarse and fine-grained entities\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">loc (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">loc.adm.town (FINE)</span>\n",
       "</mark>\n",
       " est créée \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    le 1er avril 1976\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">time (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    le 1er avril 1976\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">time.date.abs (FINE)</span>\n",
       "</mark>\n",
       " dans le garage de la maison </br>            d'enfance de \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Jobs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">pers (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Jobs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">pers.ind (FINE)</span>\n",
       "</mark>\n",
       " à \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Los Altos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">loc (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Los Altos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">loc.adm.town (FINE)</span>\n",
       "</mark>\n",
       " en \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Californie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">loc (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Californie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">loc.adm.nat (FINE)</span>\n",
       "</mark>\n",
       " par \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Jobs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">pers (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Jobs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">pers.ind (FINE)</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Wozniak\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">pers (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Wozniak\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">pers.ind (FINE)</span>\n",
       "</mark>\n",
       " </br>            et \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ronald Wayne\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">pers (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ronald Wayne\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">pers.ind (FINE)</span>\n",
       "</mark>\n",
       ", puis constituée sous forme de société \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    le 3 janvier 1977\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">time (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    le 3 janvier 1977\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">time.date.abs (FINE)</span>\n",
       "</mark>\n",
       " à l'origine </br>            sous le nom d'\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">loc (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">loc.adm.town (FINE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple Computer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">org (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple Computer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">org.ent (FINE)</span>\n",
       "</mark>\n",
       ", mais pour ses 30 ans et pour refléter la diversification </br>            de ses produits, le mot « computer » est retiré \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    le 9 janvier 2015\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">time (COARSE)</span>\n",
       "</mark>\n",
       "\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    le 9 janvier 2015\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">time.date.abs (FINE)</span>\n",
       "</mark>\n",
       ".</br>            </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import visualize_stacked_entities\n",
    "\n",
    "# Visualize stacked entities for each sentence\n",
    "for sentence in sentences:\n",
    "    results = ner(sentence)\n",
    "    \n",
    "    # Extract coarse and fine entities\n",
    "    coarse_entities = results[\"NE-COARSE-LIT\"]\n",
    "    fine_entities = results[\"NE-FINE-LIT\"]\n",
    "    \n",
    "    # Visualize the stacked entities\n",
    "    visualize_stacked_entities(sentence, coarse_entities, fine_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e61e17-ff51-490a-9756-ea00241637a0",
   "metadata": {},
   "source": [
    "## Entity Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e9b7e-9551-4342-955f-780647f53f5e",
   "metadata": {},
   "source": [
    "Further, the _Impresso_ NEL tool links these the previously found entity mentions to unique referents in Wikipedia and Wikidata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b132e2-acc8-4da3-be6a-bae0233a0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules from the transformers library\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load the tokenizer and model from the specified pre-trained model name\n",
    "# The model used here is \"https://huggingface.co/impresso-project/nel-mgenre-multilingual\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"impresso-project/nel-mgenre-multilingual\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"impresso-project/nel-mgenre-multilingual\").eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23a2d1a-56bb-4d1d-ac19-5987b8ccb369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.7.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.10-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.2.2 (from spacy)\n",
      "  Downloading thinc-8.2.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.4.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from spacy) (2.1.1)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading blis-0.7.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.2.2->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.3.5)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.19.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Collecting marisa-trie>=0.7.7 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /opt/anaconda3/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n",
      "Downloading spacy-3.7.5-cp312-cp312-macosx_11_0_arm64.whl (6.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp312-cp312-macosx_11_0_arm64.whl (41 kB)\n",
      "Downloading langcodes-3.4.1-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.10-cp312-cp312-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp312-cp312-macosx_11_0_arm64.whl (128 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp312-cp312-macosx_11_0_arm64.whl (486 kB)\n",
      "Downloading thinc-8.2.5-cp312-cp312-macosx_11_0_arm64.whl (760 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m760.6/760.6 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-macosx_11_0_arm64.whl (13.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-0.7.11-cp312-cp312-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpathlib-0.19.0-py3-none-any.whl (49 kB)\n",
      "Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading language_data-1.2.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading marisa_trie-1.2.0-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, shellingham, numpy, murmurhash, marisa-trie, cloudpathlib, catalogue, srsly, preshed, language-data, blis, typer, langcodes, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.1\n",
      "    Uninstalling numpy-2.1.1:\n",
      "      Successfully uninstalled numpy-2.1.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "impresso-essentials 0.0.2 requires numpy>=2.1.1, but you have numpy 1.26.4 which is incompatible.\n",
      "panel 1.4.4 requires bokeh<3.5.0,>=3.4.0, but you have bokeh 3.6.0 which is incompatible.\n",
      "streamlit 1.32.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.19.0 confection-0.1.5 cymem-2.0.8 langcodes-3.4.1 language-data-1.2.0 marisa-trie-1.2.0 murmurhash-1.0.10 numpy-1.26.4 preshed-3.0.9 shellingham-1.5.4 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.5 typer-0.12.5 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea29dd95-191e-4841-bdb6-06166aaaddf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting impresso-essentials\n",
      "  Using cached impresso_essentials-0.0.2-py3-none-any.whl.metadata (62 kB)\n",
      "Collecting aiohappyeyeballs>=2.4.0 (from impresso-essentials)\n",
      "  Using cached aiohappyeyeballs-2.4.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting aiohttp>=3.10.5 (from impresso-essentials)\n",
      "  Downloading aiohttp-3.10.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Collecting aioitertools>=0.12.0 (from impresso-essentials)\n",
      "  Using cached aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting aiosignal>=1.3.1 (from impresso-essentials)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: alabaster>=0.7.16 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (0.7.16)\n",
      "Collecting attrs>=24.2.0 (from impresso-essentials)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting babel>=2.16.0 (from impresso-essentials)\n",
      "  Using cached babel-2.16.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting bokeh>=3.5.2 (from impresso-essentials)\n",
      "  Using cached bokeh-3.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting boto3>=1.35.21 (from impresso-essentials)\n",
      "  Using cached boto3-1.35.29-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore>=1.35.21 (from impresso-essentials)\n",
      "  Using cached botocore-1.35.29-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting certifi>=2024.8.30 (from impresso-essentials)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting charset-normalizer>=3.3.2 (from impresso-essentials)\n",
      "  Downloading charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: click>=8.1.7 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (8.1.7)\n",
      "Collecting cloudpickle>=3.0.0 (from impresso-essentials)\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting contourpy>=1.3.0 (from impresso-essentials)\n",
      "  Downloading contourpy-1.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting dask>=2024.9.0 (from impresso-essentials)\n",
      "  Using cached dask-2024.9.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting dask-expr>=1.1.14 (from impresso-essentials)\n",
      "  Using cached dask_expr-1.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting distributed>=2024.9.0 (from impresso-essentials)\n",
      "  Using cached distributed-2024.9.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting docopt>=0.6.2 (from impresso-essentials)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docutils>=0.20.1 (from impresso-essentials)\n",
      "  Using cached docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting frozenlist>=1.4.1 (from impresso-essentials)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting fsspec>=2024.9.0 (from impresso-essentials)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting git-python>=1.0.3 (from impresso-essentials)\n",
      "  Using cached git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
      "Collecting gitdb>=4.0.11 (from impresso-essentials)\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting GitPython>=3.1.43 (from impresso-essentials)\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting idna>=3.10 (from impresso-essentials)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: imagesize>=1.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (1.4.1)\n",
      "Collecting importlib-resources>=6.4.5 (from impresso-essentials)\n",
      "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting iniconfig>=2.0.0 (from impresso-essentials)\n",
      "  Using cached iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (3.1.4)\n",
      "Requirement already satisfied: jmespath>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (1.0.1)\n",
      "Requirement already satisfied: joblib>=1.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (1.4.2)\n",
      "Collecting jsonschema>=4.23.0 (from impresso-essentials)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting jsonschema-specifications>=2023.12.1 (from impresso-essentials)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: locket>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (1.0.0)\n",
      "Collecting lz4>=4.3.3 (from impresso-essentials)\n",
      "  Downloading lz4-4.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.5 (from impresso-essentials)\n",
      "  Downloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
      "Collecting msgpack>=1.1.0 (from impresso-essentials)\n",
      "  Downloading msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting multidict>=6.1.0 (from impresso-essentials)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting nltk>=3.9.1 (from impresso-essentials)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting numpy>=2.1.1 (from impresso-essentials)\n",
      "  Downloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting packaging>=24.1 (from impresso-essentials)\n",
      "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: pandas>=2.2.2 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (2.2.2)\n",
      "Collecting partd>=1.4.2 (from impresso-essentials)\n",
      "  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting pillow>=10.4.0 (from impresso-essentials)\n",
      "  Downloading pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting pip>=24.2 (from impresso-essentials)\n",
      "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pluggy>=1.5.0 (from impresso-essentials)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting psutil>=6.0.0 (from impresso-essentials)\n",
      "  Using cached psutil-6.0.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (21 kB)\n",
      "Collecting pyarrow>=17.0.0 (from impresso-essentials)\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting Pygments>=2.18.0 (from impresso-essentials)\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pysbd>=0.3.4 (from impresso-essentials)\n",
      "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting pytest>=8.3.3 (from impresso-essentials)\n",
      "  Using cached pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.9.0.post0 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (2.9.0.post0)\n",
      "Collecting python-dotenv>=1.0.1 (from impresso-essentials)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pytz>=2024.2 (from impresso-essentials)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting PyYAML>=6.0.2 (from impresso-essentials)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting referencing>=0.35.1 (from impresso-essentials)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting regex>=2024.9.11 (from impresso-essentials)\n",
      "  Downloading regex-2024.9.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests>=2.32.3 (from impresso-essentials)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rpds-py>=0.20.0 (from impresso-essentials)\n",
      "  Downloading rpds_py-0.20.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting s3fs>=2024.9.0 (from impresso-essentials)\n",
      "  Using cached s3fs-2024.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting s3transfer>=0.10.2 (from impresso-essentials)\n",
      "  Using cached s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting setuptools>=72.1.0 (from impresso-essentials)\n",
      "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: six>=1.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (1.16.0)\n",
      "Collecting smart-open>=7.0.4 (from impresso-essentials)\n",
      "  Using cached smart_open-7.0.4-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting smmap>=5.0.1 (from impresso-essentials)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: snowballstemmer>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (2.2.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (2.4.0)\n",
      "Collecting Sphinx>=7.4.7 (from impresso-essentials)\n",
      "  Using cached sphinx-8.0.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting sphinx-rtd-theme>=2.0.0 (from impresso-essentials)\n",
      "  Using cached sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting sphinxcontrib-applehelp>=2.0.0 (from impresso-essentials)\n",
      "  Using cached sphinxcontrib_applehelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-devhelp>=2.0.0 (from impresso-essentials)\n",
      "  Using cached sphinxcontrib_devhelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.1.0 (from impresso-essentials)\n",
      "  Using cached sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-jquery>=4.1 (from impresso-essentials)\n",
      "  Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (1.0.1)\n",
      "Collecting sphinxcontrib-qthelp>=2.0.0 (from impresso-essentials)\n",
      "  Using cached sphinxcontrib_qthelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=2.0.0 (from impresso-essentials)\n",
      "  Using cached sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tblib>=3.0.0 (from impresso-essentials)\n",
      "  Using cached tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting toolz>=0.12.1 (from impresso-essentials)\n",
      "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: tornado>=6.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (6.4.1)\n",
      "Collecting tqdm>=4.66.5 (from impresso-essentials)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting tzdata>=2024.1 (from impresso-essentials)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting urllib3>=2.2.3 (from impresso-essentials)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting wheel>=0.44.0 (from impresso-essentials)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting wrapt>=1.16.0 (from impresso-essentials)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting xyzservices>=2024.9.0 (from impresso-essentials)\n",
      "  Using cached xyzservices-2024.9.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting yarl>=1.11.1 (from impresso-essentials)\n",
      "  Downloading yarl-1.13.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zict>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from impresso-essentials) (3.0.0)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /opt/anaconda3/lib/python3.12/site-packages (from s3fs>=2024.9.0->impresso-essentials) (2.12.3)\n",
      "Collecting Sphinx>=7.4.7 (from impresso-essentials)\n",
      "  Using cached sphinx-7.4.7-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting docutils>=0.20.1 (from impresso-essentials)\n",
      "  Using cached docutils-0.20.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "INFO: pip is looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2024.9.0->impresso-essentials)\n",
      "  Using cached aiobotocore-2.15.1-py3-none-any.whl.metadata (23 kB)\n",
      "  Using cached aiobotocore-2.15.0-py3-none-any.whl.metadata (23 kB)\n",
      "  Using cached aiobotocore-2.14.0-py3-none-any.whl.metadata (23 kB)\n",
      "  Using cached aiobotocore-2.13.3-py3-none-any.whl.metadata (22 kB)\n",
      "  Using cached aiobotocore-2.13.2-py3-none-any.whl.metadata (22 kB)\n",
      "  Using cached aiobotocore-2.13.1-py3-none-any.whl.metadata (22 kB)\n",
      "  Using cached aiobotocore-2.13.0-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is still looking at multiple versions of aiobotocore to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached aiobotocore-2.12.4-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached aiobotocore-2.12.2-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached aiobotocore-2.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached aiobotocore-2.12.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached aiobotocore-2.11.2-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached aiobotocore-2.11.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached aiobotocore-2.11.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Using cached aiobotocore-2.10.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached aiobotocore-2.9.1-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached aiobotocore-2.9.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached aiobotocore-2.8.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached aiobotocore-2.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached aiobotocore-2.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached aiobotocore-2.5.4-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting boto3>=1.35.21 (from impresso-essentials)\n",
      "  Using cached boto3-1.35.28-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached boto3-1.35.27-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached boto3-1.35.26-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached boto3-1.35.25-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached boto3-1.35.24-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Using cached boto3-1.35.23-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore>=1.35.21 (from impresso-essentials)\n",
      "  Using cached botocore-1.35.23-py3-none-any.whl.metadata (5.7 kB)\n",
      "Using cached impresso_essentials-0.0.2-py3-none-any.whl (111 kB)\n",
      "Using cached aiohappyeyeballs-2.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading aiohttp-3.10.8-cp312-cp312-macosx_11_0_arm64.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.7/390.7 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached babel-2.16.0-py3-none-any.whl (9.6 MB)\n",
      "Using cached bokeh-3.6.0-py3-none-any.whl (6.9 MB)\n",
      "Using cached boto3-1.35.23-py3-none-any.whl (139 kB)\n",
      "Using cached s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.3.2-cp312-cp312-macosx_11_0_arm64.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading contourpy-1.3.0-cp312-cp312-macosx_11_0_arm64.whl (251 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.5/251.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached dask-2024.9.1-py3-none-any.whl (1.3 MB)\n",
      "Using cached dask_expr-1.1.15-py3-none-any.whl (242 kB)\n",
      "Using cached distributed-2024.9.1-py3-none-any.whl (1.0 MB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-macosx_11_0_arm64.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Downloading lz4-4.3.3-cp312-cp312-macosx_11_0_arm64.whl (212 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl (18 kB)\n",
      "Downloading msgpack-1.1.0-cp312-cp312-macosx_11_0_arm64.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp312-cp312-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Using cached psutil-6.0.0-cp38-abi3-macosx_11_0_arm64.whl (251 kB)\n",
      "Downloading pyarrow-17.0.0-cp312-cp312-macosx_11_0_arm64.whl (27.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pytest-8.3.3-py3-none-any.whl (342 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.3/173.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.9.11-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.7/284.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading rpds_py-0.20.0-cp312-cp312-macosx_11_0_arm64.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.1/313.1 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached s3fs-2024.9.0-py3-none-any.whl (29 kB)\n",
      "Using cached aiobotocore-2.15.1-py3-none-any.whl (77 kB)\n",
      "Using cached botocore-1.35.23-py3-none-any.whl (12.6 MB)\n",
      "Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Using cached sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Using cached docutils-0.20.1-py3-none-any.whl (572 kB)\n",
      "Using cached sphinx-7.4.7-py3-none-any.whl (3.4 MB)\n",
      "Using cached sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n",
      "Using cached sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n",
      "Using cached sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n",
      "Using cached sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Using cached sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n",
      "Using cached sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n",
      "Using cached tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached xyzservices-2024.9.0-py3-none-any.whl (85 kB)\n",
      "Downloading yarl-1.13.1-cp312-cp312-macosx_11_0_arm64.whl (113 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.9/113.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=99360edb2b145dc85a0661e7d6b49fe387ac8b5cd9a8a4ca23e03b973e54eecb\n",
      "  Stored in directory: /Users/eboros/Library/Caches/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
      "Successfully built docopt\n",
      "Installing collected packages: pytz, docopt, xyzservices, wrapt, wheel, urllib3, tzdata, tqdm, toolz, tblib, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, smmap, setuptools, rpds-py, regex, PyYAML, python-dotenv, pysbd, Pygments, psutil, pluggy, pip, pillow, packaging, numpy, multidict, msgpack, MarkupSafe, lz4, iniconfig, importlib-resources, idna, fsspec, frozenlist, docutils, cloudpickle, charset-normalizer, certifi, babel, attrs, aioitertools, aiohappyeyeballs, yarl, smart-open, requests, referencing, pytest, pyarrow, partd, nltk, gitdb, contourpy, botocore, aiosignal, Sphinx, s3transfer, jsonschema-specifications, GitPython, dask, bokeh, aiohttp, sphinxcontrib-jquery, jsonschema, git-python, distributed, dask-expr, boto3, aiobotocore, sphinx-rtd-theme, s3fs, impresso-essentials\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: xyzservices\n",
      "    Found existing installation: xyzservices 2022.9.0\n",
      "    Uninstalling xyzservices-2022.9.0:\n",
      "      Successfully uninstalled xyzservices-2022.9.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.14.1\n",
      "    Uninstalling wrapt-1.14.1:\n",
      "      Successfully uninstalled wrapt-1.14.1\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.43.0\n",
      "    Uninstalling wheel-0.43.0:\n",
      "      Successfully uninstalled wheel-0.43.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2023.3\n",
      "    Uninstalling tzdata-2023.3:\n",
      "      Successfully uninstalled tzdata-2023.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "  Attempting uninstall: toolz\n",
      "    Found existing installation: toolz 0.12.0\n",
      "    Uninstalling toolz-0.12.0:\n",
      "      Successfully uninstalled toolz-0.12.0\n",
      "  Attempting uninstall: tblib\n",
      "    Found existing installation: tblib 1.7.0\n",
      "    Uninstalling tblib-1.7.0:\n",
      "      Successfully uninstalled tblib-1.7.0\n",
      "  Attempting uninstall: sphinxcontrib-serializinghtml\n",
      "    Found existing installation: sphinxcontrib-serializinghtml 1.1.10\n",
      "    Uninstalling sphinxcontrib-serializinghtml-1.1.10:\n",
      "      Successfully uninstalled sphinxcontrib-serializinghtml-1.1.10\n",
      "  Attempting uninstall: sphinxcontrib-qthelp\n",
      "    Found existing installation: sphinxcontrib-qthelp 1.0.3\n",
      "    Uninstalling sphinxcontrib-qthelp-1.0.3:\n",
      "      Successfully uninstalled sphinxcontrib-qthelp-1.0.3\n",
      "  Attempting uninstall: sphinxcontrib-htmlhelp\n",
      "    Found existing installation: sphinxcontrib-htmlhelp 2.0.0\n",
      "    Uninstalling sphinxcontrib-htmlhelp-2.0.0:\n",
      "      Successfully uninstalled sphinxcontrib-htmlhelp-2.0.0\n",
      "  Attempting uninstall: sphinxcontrib-devhelp\n",
      "    Found existing installation: sphinxcontrib-devhelp 1.0.2\n",
      "    Uninstalling sphinxcontrib-devhelp-1.0.2:\n",
      "      Successfully uninstalled sphinxcontrib-devhelp-1.0.2\n",
      "  Attempting uninstall: sphinxcontrib-applehelp\n",
      "    Found existing installation: sphinxcontrib-applehelp 1.0.2\n",
      "    Uninstalling sphinxcontrib-applehelp-1.0.2:\n",
      "      Successfully uninstalled sphinxcontrib-applehelp-1.0.2\n",
      "  Attempting uninstall: smmap\n",
      "    Found existing installation: smmap 4.0.0\n",
      "    Uninstalling smmap-4.0.0:\n",
      "      Successfully uninstalled smmap-4.0.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 69.5.1\n",
      "    Uninstalling setuptools-69.5.1:\n",
      "      Successfully uninstalled setuptools-69.5.1\n",
      "  Attempting uninstall: rpds-py\n",
      "    Found existing installation: rpds-py 0.10.6\n",
      "    Uninstalling rpds-py-0.10.6:\n",
      "      Successfully uninstalled rpds-py-0.10.6\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2023.10.3\n",
      "    Uninstalling regex-2023.10.3:\n",
      "      Successfully uninstalled regex-2023.10.3\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 0.21.0\n",
      "    Uninstalling python-dotenv-0.21.0:\n",
      "      Successfully uninstalled python-dotenv-0.21.0\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.15.1\n",
      "    Uninstalling Pygments-2.15.1:\n",
      "      Successfully uninstalled Pygments-2.15.1\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.0\n",
      "    Uninstalling psutil-5.9.0:\n",
      "      Successfully uninstalled psutil-5.9.0\n",
      "  Attempting uninstall: pluggy\n",
      "    Found existing installation: pluggy 1.0.0\n",
      "    Uninstalling pluggy-1.0.0:\n",
      "      Successfully uninstalled pluggy-1.0.0\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.3.0\n",
      "    Uninstalling pillow-10.3.0:\n",
      "      Successfully uninstalled pillow-10.3.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.2\n",
      "    Uninstalling packaging-23.2:\n",
      "      Successfully uninstalled packaging-23.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.4\n",
      "    Uninstalling multidict-6.0.4:\n",
      "      Successfully uninstalled multidict-6.0.4\n",
      "  Attempting uninstall: msgpack\n",
      "    Found existing installation: msgpack 1.0.3\n",
      "    Uninstalling msgpack-1.0.3:\n",
      "      Successfully uninstalled msgpack-1.0.3\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.3\n",
      "    Uninstalling MarkupSafe-2.1.3:\n",
      "      Successfully uninstalled MarkupSafe-2.1.3\n",
      "  Attempting uninstall: lz4\n",
      "    Found existing installation: lz4 4.3.2\n",
      "    Uninstalling lz4-4.3.2:\n",
      "      Successfully uninstalled lz4-4.3.2\n",
      "  Attempting uninstall: iniconfig\n",
      "    Found existing installation: iniconfig 1.1.1\n",
      "    Uninstalling iniconfig-1.1.1:\n",
      "      Successfully uninstalled iniconfig-1.1.1\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.7\n",
      "    Uninstalling idna-3.7:\n",
      "      Successfully uninstalled idna-3.7\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.3.1\n",
      "    Uninstalling fsspec-2024.3.1:\n",
      "      Successfully uninstalled fsspec-2024.3.1\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.4.0\n",
      "    Uninstalling frozenlist-1.4.0:\n",
      "      Successfully uninstalled frozenlist-1.4.0\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.18.1\n",
      "    Uninstalling docutils-0.18.1:\n",
      "      Successfully uninstalled docutils-0.18.1\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 2.2.1\n",
      "    Uninstalling cloudpickle-2.2.1:\n",
      "      Successfully uninstalled cloudpickle-2.2.1\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.0.4\n",
      "    Uninstalling charset-normalizer-2.0.4:\n",
      "      Successfully uninstalled charset-normalizer-2.0.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.6.2\n",
      "    Uninstalling certifi-2024.6.2:\n",
      "      Successfully uninstalled certifi-2024.6.2\n",
      "  Attempting uninstall: babel\n",
      "    Found existing installation: Babel 2.11.0\n",
      "    Uninstalling Babel-2.11.0:\n",
      "      Successfully uninstalled Babel-2.11.0\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "  Attempting uninstall: aioitertools\n",
      "    Found existing installation: aioitertools 0.7.1\n",
      "    Uninstalling aioitertools-0.7.1:\n",
      "      Successfully uninstalled aioitertools-0.7.1\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.9.3\n",
      "    Uninstalling yarl-1.9.3:\n",
      "      Successfully uninstalled yarl-1.9.3\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 5.2.1\n",
      "    Uninstalling smart-open-5.2.1:\n",
      "      Successfully uninstalled smart-open-5.2.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.2\n",
      "    Uninstalling requests-2.32.2:\n",
      "      Successfully uninstalled requests-2.32.2\n",
      "  Attempting uninstall: referencing\n",
      "    Found existing installation: referencing 0.30.2\n",
      "    Uninstalling referencing-0.30.2:\n",
      "      Successfully uninstalled referencing-0.30.2\n",
      "  Attempting uninstall: pytest\n",
      "    Found existing installation: pytest 7.4.4\n",
      "    Uninstalling pytest-7.4.4:\n",
      "      Successfully uninstalled pytest-7.4.4\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "  Attempting uninstall: partd\n",
      "    Found existing installation: partd 1.4.1\n",
      "    Uninstalling partd-1.4.1:\n",
      "      Successfully uninstalled partd-1.4.1\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  Attempting uninstall: gitdb\n",
      "    Found existing installation: gitdb 4.0.7\n",
      "    Uninstalling gitdb-4.0.7:\n",
      "      Successfully uninstalled gitdb-4.0.7\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.2.0\n",
      "    Uninstalling contourpy-1.2.0:\n",
      "      Successfully uninstalled contourpy-1.2.0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.69\n",
      "    Uninstalling botocore-1.34.69:\n",
      "      Successfully uninstalled botocore-1.34.69\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.2.0\n",
      "    Uninstalling aiosignal-1.2.0:\n",
      "      Successfully uninstalled aiosignal-1.2.0\n",
      "  Attempting uninstall: Sphinx\n",
      "    Found existing installation: Sphinx 7.3.7\n",
      "    Uninstalling Sphinx-7.3.7:\n",
      "      Successfully uninstalled Sphinx-7.3.7\n",
      "  Attempting uninstall: jsonschema-specifications\n",
      "    Found existing installation: jsonschema-specifications 2023.7.1\n",
      "    Uninstalling jsonschema-specifications-2023.7.1:\n",
      "      Successfully uninstalled jsonschema-specifications-2023.7.1\n",
      "  Attempting uninstall: GitPython\n",
      "    Found existing installation: GitPython 3.1.37\n",
      "    Uninstalling GitPython-3.1.37:\n",
      "      Successfully uninstalled GitPython-3.1.37\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2024.5.0\n",
      "    Uninstalling dask-2024.5.0:\n",
      "      Successfully uninstalled dask-2024.5.0\n",
      "  Attempting uninstall: bokeh\n",
      "    Found existing installation: bokeh 3.4.1\n",
      "    Uninstalling bokeh-3.4.1:\n",
      "      Successfully uninstalled bokeh-3.4.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.9.5\n",
      "    Uninstalling aiohttp-3.9.5:\n",
      "      Successfully uninstalled aiohttp-3.9.5\n",
      "  Attempting uninstall: jsonschema\n",
      "    Found existing installation: jsonschema 4.19.2\n",
      "    Uninstalling jsonschema-4.19.2:\n",
      "      Successfully uninstalled jsonschema-4.19.2\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2024.5.0\n",
      "    Uninstalling distributed-2024.5.0:\n",
      "      Successfully uninstalled distributed-2024.5.0\n",
      "  Attempting uninstall: dask-expr\n",
      "    Found existing installation: dask-expr 1.1.0\n",
      "    Uninstalling dask-expr-1.1.0:\n",
      "      Successfully uninstalled dask-expr-1.1.0\n",
      "  Attempting uninstall: aiobotocore\n",
      "    Found existing installation: aiobotocore 2.12.3\n",
      "    Uninstalling aiobotocore-2.12.3:\n",
      "      Successfully uninstalled aiobotocore-2.12.3\n",
      "  Attempting uninstall: s3fs\n",
      "    Found existing installation: s3fs 2024.3.1\n",
      "    Uninstalling s3fs-2024.3.1:\n",
      "      Successfully uninstalled s3fs-2024.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "panel 1.4.4 requires bokeh<3.5.0,>=3.4.0, but you have bokeh 3.6.0 which is incompatible.\n",
      "streamlit 1.32.0 requires numpy<2,>=1.19.3, but you have numpy 2.1.1 which is incompatible.\n",
      "streamlit 1.32.0 requires packaging<24,>=16.8, but you have packaging 24.1 which is incompatible.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.1.1 which is incompatible.\n",
      "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed GitPython-3.1.43 MarkupSafe-2.1.5 PyYAML-6.0.2 Pygments-2.18.0 Sphinx-7.4.7 aiobotocore-2.15.1 aiohappyeyeballs-2.4.2 aiohttp-3.10.8 aioitertools-0.12.0 aiosignal-1.3.1 attrs-24.2.0 babel-2.16.0 bokeh-3.6.0 boto3-1.35.23 botocore-1.35.23 certifi-2024.8.30 charset-normalizer-3.3.2 cloudpickle-3.0.0 contourpy-1.3.0 dask-2024.9.1 dask-expr-1.1.15 distributed-2024.9.1 docopt-0.6.2 docutils-0.20.1 frozenlist-1.4.1 fsspec-2024.9.0 git-python-1.0.3 gitdb-4.0.11 idna-3.10 importlib-resources-6.4.5 impresso-essentials-0.0.2 iniconfig-2.0.0 jsonschema-4.23.0 jsonschema-specifications-2023.12.1 lz4-4.3.3 msgpack-1.1.0 multidict-6.1.0 nltk-3.9.1 numpy-2.1.1 packaging-24.1 partd-1.4.2 pillow-10.4.0 pip-24.2 pluggy-1.5.0 psutil-6.0.0 pyarrow-17.0.0 pysbd-0.3.4 pytest-8.3.3 python-dotenv-1.0.1 pytz-2024.2 referencing-0.35.1 regex-2024.9.11 requests-2.32.3 rpds-py-0.20.0 s3fs-2024.9.0 s3transfer-0.10.2 setuptools-75.1.0 smart-open-7.0.4 smmap-5.0.1 sphinx-rtd-theme-2.0.0 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jquery-4.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 tblib-3.0.0 toolz-0.12.1 tqdm-4.66.5 tzdata-2024.2 urllib3-2.2.3 wheel-0.44.0 wrapt-1.16.0 xyzservices-2024.9.0 yarl-1.13.1\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install impresso-essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b1496a-7c4b-4e09-83d6-4d2aa5c5a6fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimpresso_essentials\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tokenise\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Process each sentence for named entity recognition and linking\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m sentences:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Input text to be processed for named entity recognition\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentence\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Run the NER pipeline on the input sentence and store the results\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentences' is not defined"
     ]
    }
   ],
   "source": [
    "from impresso_essentials.text_utils import tokenise\n",
    "\n",
    "# Process each sentence for named entity recognition and linking\n",
    "for sentence in sentences:\n",
    "    # Input text to be processed for named entity recognition\n",
    "    print(f'Sentence: {sentence}')\n",
    "    \n",
    "    # Run the NER pipeline on the input sentence and store the results\n",
    "    results = ner(sentence)\n",
    "\n",
    "    # Initialize a list to hold the entities\n",
    "    entities = []\n",
    "\n",
    "    # Extract entities from the results\n",
    "    for task, ents in results.items():\n",
    "        for entity in ents:\n",
    "            entities.append((entity['start'], entity['end'], entity['word']))\n",
    "    \n",
    "    # List to keep track of already processed words to avoid duplicate tagging\n",
    "    already_done = []\n",
    "\n",
    "    # Process each entity for linking\n",
    "    for start, end, word in entities:\n",
    "        if word not in already_done:\n",
    "            # Tag the entity in the text\n",
    "\n",
    "            tokens = tokenise(sentence, language)\n",
    "            start, end = (\n",
    "                entity[\"index\"][0],\n",
    "                entity[\"index\"][1],\n",
    "            )\n",
    "\n",
    "            context_start = max(0, start - 10)\n",
    "            context_end = min(len(tokens), end + 11)\n",
    "\n",
    "            nel_sentence = (\n",
    "                \" \".join(tokens[context_start:start])\n",
    "                + \" [START] \"\n",
    "                + remove_end_punctuation(entity_text)\n",
    "                + \" [END] \"\n",
    "                + \" \".join(tokens[end + 1 : context_end])\n",
    "            )\n",
    "            \n",
    "            # Generate Wikipedia links for the tagged text\n",
    "            outputs = model.generate(\n",
    "                **tokenizer([nel_sentence], return_tensors=\"pt\"),\n",
    "                num_beams=3,\n",
    "                num_return_sequences=5\n",
    "            )\n",
    "            \n",
    "            # Decode the generated output to get the Wikipedia links\n",
    "            wikipedia_links = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            print(f\"\\nEntity: {word}, Wikipedia Links: {wikipedia_links}\")\n",
    "            \n",
    "            # Add the word to the already processed list\n",
    "            already_done.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cc5b742-26af-4017-b204-12a0e460bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Apple est créée le 1er avril 1976 dans le garage de la maison \n",
      "            d'enfance de Steve Jobs à Los Altos en Californie par Steve Jobs, Steve Wozniak \n",
      "            et Ronald Wayne, puis constituée sous forme de société le 3 janvier 1977 à l'origine \n",
      "            sous le nom d'Apple Computer, mais pour ses 30 ans et pour refléter la diversification \n",
      "            de ses produits, le mot « computer » est retiré le 9 janvier 2015.\n",
      "            \n",
      "\n",
      "Entity: Apple, Wikipedia Links: ['Apple >> fr ', 'Apple Inc. >> fr ', 'Apple Corporation >> fr ', 'Apple Group >> fr ', 'Apple Corps >> fr ']\n",
      "  Wikidata: Apple >> fr  -> Q312\n",
      "  Wikidata: Apple Inc. >> fr  -> NIL\n",
      "  Wikidata: Apple Corporation >> fr  -> NIL\n",
      "  Wikidata: Apple Group >> fr  -> NIL\n",
      "  Wikidata: Apple Corps >> fr  -> Q621231\n",
      "\n",
      "Entity: le 1er avril 1976, Wikipedia Links: ['le 1er avril 1976 >> fr ', '1er avril 1976 >> fr ', 'Le 1er avril 1976 >> fr ', '1 avril 1976 >> fr ', 'Avril 1976 >> fr ']\n",
      "  Wikidata: le 1er avril 1976 >> fr  -> NIL\n",
      "  Wikidata: 1er avril 1976 >> fr  -> NIL\n",
      "  Wikidata: Le 1er avril 1976 >> fr  -> NIL\n",
      "  Wikidata: 1 avril 1976 >> fr  -> NIL\n",
      "  Wikidata: Avril 1976 >> fr  -> Q13080426\n",
      "\n",
      "Entity: Steve Jobs, Wikipedia Links: ['Steve Jobs >> fr ', 'Steve Job >> fr ', 'Steve Steve Jobs >> fr ', 'Stephen Jobs >> fr ', 'Steven Jobs >> fr ']\n",
      "  Wikidata: Steve Jobs >> fr  -> Q19837\n",
      "  Wikidata: Steve Job >> fr  -> NIL\n",
      "  Wikidata: Steve Steve Jobs >> fr  -> NIL\n",
      "  Wikidata: Stephen Jobs >> fr  -> NIL\n",
      "  Wikidata: Steven Jobs >> fr  -> NIL\n",
      "\n",
      "Entity: Los Altos, Wikipedia Links: ['Los Altos >> fr ', 'Apple Los Altos >> fr ', 'Los Altos (Californie) >> fr ', 'Los Altos >> fr ', 'Los Altos (Califórnia) >> fr ']\n",
      "  Wikidata: Los Altos >> fr  -> Q299298\n",
      "  Wikidata: Apple Los Altos >> fr  -> NIL\n",
      "  Wikidata: Los Altos (Californie) >> fr  -> Q864124\n",
      "  Wikidata: Los Altos >> fr  -> Q299298\n",
      "  Wikidata: Los Altos (Califórnia) >> fr  -> NIL\n",
      "\n",
      "Entity: Californie, Wikipedia Links: ['Californie >> fr ', 'Californië >> fr ', 'California >> fr ', 'Kalifornie >> fr ', 'Californe >> fr ']\n",
      "  Wikidata: Californie >> fr  -> Q99\n",
      "  Wikidata: Californië >> fr  -> NIL\n",
      "  Wikidata: California >> fr  -> Q1026787\n",
      "  Wikidata: Kalifornie >> fr  -> NIL\n",
      "  Wikidata: Californe >> fr  -> NIL\n",
      "\n",
      "Entity: Steve Wozniak, Wikipedia Links: ['Steve Wozniak >> fr ', 'Stephen Wozniak >> fr ', 'Steven Wozniak >> fr ', 'Steve Wbonak >> fr ', 'Steve Wbonek >> fr ']\n",
      "  Wikidata: Steve Wozniak >> fr  -> Q483382\n",
      "  Wikidata: Stephen Wozniak >> fr  -> NIL\n",
      "  Wikidata: Steven Wozniak >> fr  -> NIL\n",
      "  Wikidata: Steve Wbonak >> fr  -> NIL\n",
      "  Wikidata: Steve Wbonek >> fr  -> NIL\n",
      "\n",
      "Entity: Ronald Wayne, Wikipedia Links: ['Ronnie Wayne >> fr ', 'Ron Wayne >> fr ', 'Ronald Wayne >> fr ', 'Ron Weyne >> fr ', 'Ronny Wayne >> fr ']\n",
      "  Wikidata: Ronnie Wayne >> fr  -> NIL\n",
      "  Wikidata: Ron Wayne >> fr  -> NIL\n",
      "  Wikidata: Ronald Wayne >> fr  -> Q332591\n",
      "  Wikidata: Ron Weyne >> fr  -> NIL\n",
      "  Wikidata: Ronny Wayne >> fr  -> NIL\n",
      "\n",
      "Entity: le 3 janvier 1977, Wikipedia Links: ['le 3 janvier 1977 >> fr ', 'le 3 janvier 1977 >> fr ', 'du 3 janvier 1977 >> fr ', 'le 3 janvier 1977 de janvier 2008 à Los Angeles >> fr ', '3 janvier 1977 >> fr ']\n",
      "  Wikidata: le 3 janvier 1977 >> fr  -> NIL\n",
      "  Wikidata: le 3 janvier 1977 >> fr  -> NIL\n",
      "  Wikidata: du 3 janvier 1977 >> fr  -> NIL\n",
      "  Wikidata: le 3 janvier 1977 de janvier 2008 à Los Angeles >> fr  -> NIL\n",
      "  Wikidata: 3 janvier 1977 >> fr  -> NIL\n",
      "\n",
      "Entity: Apple Computer, Wikipedia Links: ['Apple >> fr ', \"Apple (système d'exploitation) >> fr \", \"Apple (système d'arcade) >> fr \", \"Apple (système d'agrès d'enseignes) >> fr\", \"Apple (système d'agglomération) >> fr \"]\n",
      "  Wikidata: Apple >> fr  -> Q312\n",
      "  Wikidata: Apple (système d'exploitation) >> fr  -> NIL\n",
      "  Wikidata: Apple (système d'arcade) >> fr  -> NIL\n",
      "  Wikidata: Apple (système d'agrès d'enseignes) >> fr -> NIL\n",
      "  Wikidata: Apple (système d'agglomération) >> fr  -> NIL\n",
      "\n",
      "Entity: le 9 janvier 2015, Wikipedia Links: ['le 9 janvier 2015 >> fr ', 'Apple >> fr ', '„ le 9 janvier 2015 >> fr ', 'dit le 9 janvier 2015 >> fr ', 'janvier 2015 >> fr ']\n",
      "  Wikidata: le 9 janvier 2015 >> fr  -> NIL\n",
      "  Wikidata: Apple >> fr  -> Q312\n",
      "  Wikidata: „ le 9 janvier 2015 >> fr  -> NIL\n",
      "  Wikidata: dit le 9 janvier 2015 >> fr  -> NIL\n",
      "  Wikidata: janvier 2015 >> fr  -> Q15043331\n"
     ]
    }
   ],
   "source": [
    "from utils import get_wikipedia_page_props\n",
    "\n",
    "# Process each sentence for named entity recognition and linking\n",
    "for sentence in sentences:\n",
    "    # Input text to be processed for named entity recognition\n",
    "    print(f'Sentence: {sentence}')\n",
    "    \n",
    "    # Run the NER pipeline on the input sentence and store the results\n",
    "    results = ner(sentence)\n",
    "\n",
    "    # Initialize a list to hold the entities\n",
    "    entities = []\n",
    "\n",
    "    # Extract entities from the results\n",
    "    for task, ents in results.items():\n",
    "        for entity in ents:\n",
    "            entities.append((entity['start'], entity['end'], entity['word']))\n",
    "    \n",
    "    # List to keep track of already processed words to avoid duplicate tagging\n",
    "    already_done = []\n",
    "\n",
    "    # Process each entity for linking\n",
    "    for start, end, word in entities:\n",
    "        if word not in already_done:\n",
    "            # Tag the entity in the text\n",
    "            entity_text = sentence.replace(word, f\"[START] {word} [END]\")\n",
    "            # print(f\"\\nEntity: {word}, Tagged Text: {entity_text}\\n\")\n",
    "\n",
    "            # Generate Wikipedia links for the tagged text\n",
    "            outputs = model.generate(\n",
    "                **tokenizer([entity_text], return_tensors=\"pt\"),\n",
    "                num_beams=5,\n",
    "                num_return_sequences=5\n",
    "            )\n",
    "            \n",
    "            # Decode the generated output to get the Wikipedia links\n",
    "            wikipedia_links = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "            print(f\"\\nEntity: {word}, Wikipedia Links: {wikipedia_links}\")\n",
    "            \n",
    "            # Add the word to the already processed list\n",
    "            already_done.append(word)\n",
    "            \n",
    "            # Retrieve and print Wikidata QID for each Wikipedia link\n",
    "            for wikipedia_link in wikipedia_links:\n",
    "                qid = get_wikipedia_page_props(wikipedia_link)\n",
    "                print(f\"  Wikidata: {wikipedia_link} -> {qid}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0238bf-c4d6-4bc3-b4ed-df8b05c0b4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bdb43f-da8e-4f49-8a61-325bd2289ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725503fb-acdc-4c0e-abf4-ecdd56718acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
