{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/flipz357/impresso-datalab-notebooks/blob/main/3.1-language-identification/floret-language-identification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0CKTXyqcKFt"
      },
      "source": [
        "# Language Identification using Floret\n",
        "\n",
        "This notebook demonstrates how to use a pre-trained Floret language identification model downloaded from Hugging Face.\n",
        "We'll load the model, input some text, and predict the language of the text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUhHooDycRCt"
      },
      "source": [
        "## 1. Install Dependencies\n",
        "\n",
        "First, we need to install `floret` and `huggingface_hub` to work with the Floret language identification model and Hugging Face.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKvs0oPhawd_",
        "outputId": "020ffb45-78b4-45aa-a07a-1df1a08d2d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting floret\n",
            "  Downloading floret-0.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from floret) (1.26.4)\n",
            "Downloading floret-0.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (320 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/320.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: floret\n",
            "Successfully installed floret-0.10.5\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install floret\n",
        "!pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-3c3dhacYsJ"
      },
      "source": [
        "## 2. Model Information\n",
        "\n",
        "In this example, we are using a language identification model hosted on the Hugging Face Hub: `impresso-project/impresso-floret-langident`.\n",
        "The model can predict the language of a given text of a reasonable length and supports the main impresso languages: German (de), French (fr), Luxemburgish (lb), Italian (it), English (en)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5cxq30rch9r"
      },
      "source": [
        "## 3. Defining the FloretLangIdentifier Class\n",
        "\n",
        "This class downloads the Floret model from Hugging Face and loads it for prediction. We use `huggingface_hub` to download the model locally.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "dKdWzGvUbFkU"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "import floret\n",
        "\n",
        "\n",
        "class FloretLangIdentifier:\n",
        "    def __init__(self, repo_id, model_filename):\n",
        "        \"\"\"\n",
        "        Initialize the Floret language identification model by downloading it from Hugging Face.\n",
        "        Args:\n",
        "            repo_id (str): The Hugging Face repository ID (e.g., \"username/repo_name\").\n",
        "            model_filename (str): The model file name in the repository (e.g., \"model.bin\").\n",
        "        \"\"\"\n",
        "        model_path = self._download_model(repo_id, model_filename)\n",
        "        self.model = floret.load_model(model_path)\n",
        "\n",
        "    def _download_model(self, repo_id, model_filename):\n",
        "        \"\"\"\n",
        "        Download the model file from Hugging Face using huggingface_hub.\n",
        "        Args:\n",
        "            repo_id (str): The repository ID from which to download the model.\n",
        "            model_filename (str): The model filename in the Hugging Face repository.\n",
        "\n",
        "        Returns:\n",
        "            str: The local path to the downloaded model file.\n",
        "        \"\"\"\n",
        "        local_model_path = hf_hub_download(repo_id=repo_id, filename=model_filename)\n",
        "        return local_model_path\n",
        "\n",
        "    def predict(self, text):\n",
        "        \"\"\"\n",
        "        Predict the language of the input text.\n",
        "        Args:\n",
        "            text (str): The input text.\n",
        "\n",
        "        Returns:\n",
        "            List of predicted labels and their probabilities.\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(text)\n",
        "        return predictions\n",
        "\n",
        "    def predict_language(self, text):\n",
        "        \"\"\"\n",
        "        Predicts the language of the input text and returns the language code without the \"__label__\" prefix.\n",
        "\n",
        "        Args:\n",
        "            text (str): The input text.\n",
        "\n",
        "        Returns:\n",
        "            str: The predicted language code (e.g., \"en\" for English).\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(text)\n",
        "        if predictions:\n",
        "            # Extract the language code from the top prediction\n",
        "            language = predictions[0][0].replace(\"__label__\", \"\")\n",
        "            return language\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def predict_language_mix(self, text, max_results=5, threshold_others=0.1):\n",
        "        \"\"\"\n",
        "        Predicts the languageS of the input text and returns the language codes without the \"__label__\" prefix.\n",
        "\n",
        "        Args:\n",
        "            text (str): The input text.\n",
        "            max_results (int): How many languages to consider?\n",
        "            threshold_others (float): Below this probability, we ignore a predicted language.\n",
        "\n",
        "        Returns:\n",
        "            list: The predicted language codes (e.g., [\"en\", \"de\"] for English and German mixed text).\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(text, k=max_results)\n",
        "        language_mix = []\n",
        "        if predictions:\n",
        "            for (i, pred) in enumerate(predictions[0]):\n",
        "                # Extract the language code\n",
        "                prob = predictions[1][i]\n",
        "                if i > 0  and prob < threshold_others:\n",
        "                    break\n",
        "                language_mix.append(pred.replace(\"__label__\", \"\"))\n",
        "            return language_mix\n",
        "        else:\n",
        "            return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgalRK6vcIYm"
      },
      "source": [
        "## 4. Using the Model for Prediction\n",
        "\n",
        "Now that the model is loaded, you can input your own text and predict the language.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Predict the main language of a document"
      ],
      "metadata": {
        "id": "OjIB8neZGtvr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "JvCLxlW6aym7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a903b1-994c-4320-d350-73ec95cca0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language: de\n"
          ]
        }
      ],
      "source": [
        "# Define the repository and model file\n",
        "repo_id = \"impresso-project/impresso-floret-langident\"\n",
        "model_filename = \"LID-40-3-2000000-1-4.bin\"\n",
        "\n",
        "# Initialize the FloretLangIdentifier with the repo and model file name\n",
        "model = FloretLangIdentifier(repo_id, model_filename)\n",
        "\n",
        "# Example text for prediction\n",
        "text = \"Das ist ein Testsatz.\"\n",
        "\n",
        "# Predict the language\n",
        "result = model.predict_language(text)\n",
        "print(\"Language:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Predict the language mix of a document\n"
      ],
      "metadata": {
        "id": "SrzlDcLKG2Nf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-output for predicting mixed-language documents\n",
        "# Example text for prediction\n",
        "text = \"This is ein test Satz.\"\n",
        "\n",
        "# Predict the language\n",
        "result = model.predict_language_mix(text)\n",
        "print(\"Language mix:\", result)"
      ],
      "metadata": {
        "id": "Qz5vkYLzGWy6",
        "outputId": "446f107c-71aa-416d-a3c6-d1d620e39fa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Language mix: ['de', 'en']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Interactive mode"
      ],
      "metadata": {
        "id": "VsxH67u2G8OS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "sndiXfDta-TZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82ebc68-f8ad-463b-aad3-a40bc6031122"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence for language identification: satz.\n",
            "Prediction Result: ['it', 'de']\n"
          ]
        }
      ],
      "source": [
        "# Interactive text input\n",
        "text = input(\"Enter a sentence for language identification: \")\n",
        "result = model.predict_language_mix(text)\n",
        "print(\"Prediction Result:\", result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZygYQTZAc5Fz"
      },
      "source": [
        "## 5. Summary and Next Steps\n",
        "\n",
        "In this notebook, we used a pre-trained Floret language identification model to predict the language of input text. You can modify the input or explore other models from Hugging Face.\n",
        "\n",
        "Feel free to try other datasets, text, or languages to experiment with the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOHoTsq6cvIG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}